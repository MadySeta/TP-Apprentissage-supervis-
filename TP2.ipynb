{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import feature_selection\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all = pd.read_csv(\"./acsincome_ca_features.csv\")\n",
    "y_all = pd.read_csv(\"./acsincome_ca_labels.csv\")\n",
    "\n",
    "X_all, y_all = shuffle(X_all, y_all, random_state=1)\n",
    "\n",
    "num_samples = int(len(X_all)*0.01)\n",
    "X, y = X_all[:num_samples], y_all[:num_samples]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = y_train['PINCP'].values\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = y_test['PINCP'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1 - Explicabilité des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient de corrélation entre features et label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_label = np.corrcoef(X_test, y_test, rowvar=False)[: -1, -1]\n",
    "correlation_df = pd.DataFrame({\"Feature\" : X.columns, \"correlation\" : correlation_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: \n",
      "  Feature  correlation\n",
      "0    AGEP     0.264362\n",
      "1     COW     0.128665\n",
      "2    SCHL     0.376713\n",
      "3     MAR    -0.283184\n",
      "4    OCCP    -0.329998\n",
      "5    POBP     0.008443\n",
      "6    RELP    -0.200241\n",
      "7    WKHP     0.411818\n",
      "8     SEX    -0.085003\n",
      "9   RAC1P    -0.040897\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation: \")\n",
    "print(correlation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient de corrélation entre features et label prédit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GdB_model = GradientBoostingClassifier(criterion= 'friedman_mse', learning_rate= 0.01, loss= 'deviance', n_estimators=500)\n",
    "GdB_model.fit(X_train, y_train)\n",
    "y_predict = GdB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_gdb = np.corrcoef(X_test, y_predict, rowvar=False)[: -1, -1]\n",
    "correlation_df_gdb = pd.DataFrame({\"Feature\" : X.columns, \"correlation\" : correlation_gdb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation gdb: \n",
      "   Feature  correlation\n",
      "0    AGEP     0.204070\n",
      "1     COW     0.042642\n",
      "2    SCHL     0.471732\n",
      "3     MAR    -0.265245\n",
      "4    OCCP    -0.589933\n",
      "5    POBP    -0.119144\n",
      "6    RELP    -0.273018\n",
      "7    WKHP     0.414855\n",
      "8     SEX    -0.051640\n",
      "9   RAC1P    -0.149184\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation gdb: \\n {correlation_df_gdb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AdB_model = AdaBoostClassifier(learning_rate= 0.5, n_estimators= 50)\n",
    "AdB_model.fit(X_train, y_train)\n",
    "y_predict = AdB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_adb = np.corrcoef(X_test, y_predict, rowvar=False)[: -1, -1]\n",
    "correlation_df_adb = pd.DataFrame({\"Feature\" : X.columns, \"correlation\" : correlation_adb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Adb: \n",
      "   Feature  correlation\n",
      "0    AGEP     0.214495\n",
      "1     COW     0.087596\n",
      "2    SCHL     0.488184\n",
      "3     MAR    -0.284715\n",
      "4    OCCP    -0.602938\n",
      "5    POBP    -0.123028\n",
      "6    RELP    -0.238265\n",
      "7    WKHP     0.395772\n",
      "8     SEX    -0.049350\n",
      "9   RAC1P    -0.179422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation Adb: \\n {correlation_df_adb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_model = SVC(C = 1, gamma= 'scale', kernel= 'rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_predict = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_svm = np.corrcoef(X_test, y_predict, rowvar=False)[: -1, -1]\n",
    "correlation_df_svm = pd.DataFrame({\"Feature\" : X.columns, \"correlation\" : correlation_svm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation svm: \n",
      "   Feature  correlation\n",
      "0    AGEP     0.207672\n",
      "1     COW     0.024466\n",
      "2    SCHL     0.437549\n",
      "3     MAR    -0.330393\n",
      "4    OCCP    -0.563285\n",
      "5    POBP    -0.140495\n",
      "6    RELP    -0.350600\n",
      "7    WKHP     0.393914\n",
      "8     SEX    -0.083008\n",
      "9   RAC1P    -0.154656\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation svm: \\n {correlation_df_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdf_model = RandomForestClassifier(criterion= 'gini', max_depth= 100, min_samples_split= 10, n_estimators= 500)\n",
    "rdf_model.fit(X_train, y_train)\n",
    "y_predict = rdf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_rdf = np.corrcoef(X_test, y_predict, rowvar=False)[: -1, -1]\n",
    "correlation_df_rdf = pd.DataFrame({\"Feature\" : X.columns, \"correlation\" : correlation_rdf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Random Forest: \n",
      "   Feature  correlation\n",
      "0    AGEP     0.183343\n",
      "1     COW     0.021266\n",
      "2    SCHL     0.450501\n",
      "3     MAR    -0.317877\n",
      "4    OCCP    -0.569221\n",
      "5    POBP    -0.154960\n",
      "6    RELP    -0.283800\n",
      "7    WKHP     0.408049\n",
      "8     SEX    -0.057461\n",
      "9   RAC1P    -0.138398\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation Random Forest: \\n {correlation_df_rdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: \n",
      "   Feature     label  Grandient Boosting  AdaBoost       SVM  Random Forest\n",
      "0    AGEP  0.264362            0.204070  0.214495  0.207672       0.183343\n",
      "1     COW  0.128665            0.042642  0.087596  0.024466       0.021266\n",
      "2    SCHL  0.376713            0.471732  0.488184  0.437549       0.450501\n",
      "3     MAR -0.283184           -0.265245 -0.284715 -0.330393      -0.317877\n",
      "4    OCCP -0.329998           -0.589933 -0.602938 -0.563285      -0.569221\n",
      "5    POBP  0.008443           -0.119144 -0.123028 -0.140495      -0.154960\n",
      "6    RELP -0.200241           -0.273018 -0.238265 -0.350600      -0.283800\n",
      "7    WKHP  0.411818            0.414855  0.395772  0.393914       0.408049\n",
      "8     SEX -0.085003           -0.051640 -0.049350 -0.083008      -0.057461\n",
      "9   RAC1P -0.040897           -0.149184 -0.179422 -0.154656      -0.138398\n"
     ]
    }
   ],
   "source": [
    "correlation_df_all = pd.DataFrame({\"Feature\" : X.columns, \n",
    "                                   \"label\" : correlation_label, \n",
    "                                   \"Grandient Boosting\" : correlation_gdb,\n",
    "                                   \"AdaBoost\": correlation_adb,\n",
    "                                   \"SVM\": correlation_svm,\n",
    "                                   \"Random Forest\" : correlation_rdf})\n",
    "print(f\"Correlation coefficient: \\n {correlation_df_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_model = SVC(C = 1, gamma= 'auto', kernel= 'rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "permutation_result = permutation_importance(svm_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of feature importance over 5 repeats \n",
      "   Feature   permutation\n",
      "0    AGEP -4.081633e-03\n",
      "1     COW -9.693878e-03\n",
      "2    SCHL  4.540816e-02\n",
      "3     MAR  1.530612e-02\n",
      "4    OCCP  2.806122e-02\n",
      "5    POBP -5.612245e-03\n",
      "6    RELP  1.173469e-02\n",
      "7    WKHP  5.459184e-02\n",
      "8     SEX  1.377551e-02\n",
      "9   RAC1P -6.661338e-17\n"
     ]
    }
   ],
   "source": [
    "mean_permutation_result_svm = pd.DataFrame({\"Feature\" : X.columns, \"permutation\" :permutation_result.importances_mean})\n",
    "print(f\"Mean of feature importance over 5 repeats \\n {mean_permutation_result_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO : the same for the AdaBost, GradientBoost and RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_model = AdaBoostClassifier(learning_rate= 0.5, n_estimators= 50)\n",
    "adb_model.fit(X_train, y_train)\n",
    "permutation_result = permutation_importance(adb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of feature importance over 5 repeats \n",
      "   Feature  permutation\n",
      "0    AGEP     0.008163\n",
      "1     COW    -0.004082\n",
      "2    SCHL     0.019898\n",
      "3     MAR     0.002551\n",
      "4    OCCP     0.009694\n",
      "5    POBP     0.004082\n",
      "6    RELP     0.002041\n",
      "7    WKHP     0.043367\n",
      "8     SEX     0.002551\n",
      "9   RAC1P     0.000000\n"
     ]
    }
   ],
   "source": [
    "mean_permutation_result_adb = pd.DataFrame({\"Feature\" : X.columns, \"permutation\" :permutation_result.importances_mean})\n",
    "print(f\"Mean of feature importance over 5 repeats \\n {mean_permutation_result_adb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_model = GradientBoostingClassifier(criterion= 'friedman_mse', learning_rate= 0.01, loss= 'deviance', n_estimators=500)\n",
    "gdb_model.fit(X_train, y_train)\n",
    "permutation_result = permutation_importance(gdb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of feature importance over 5 repeats \n",
      "   Feature  permutation\n",
      "0    AGEP     0.007653\n",
      "1     COW     0.008673\n",
      "2    SCHL     0.042857\n",
      "3     MAR     0.003061\n",
      "4    OCCP     0.044898\n",
      "5    POBP    -0.003061\n",
      "6    RELP     0.010204\n",
      "7    WKHP     0.050510\n",
      "8     SEX     0.003061\n",
      "9   RAC1P     0.000000\n"
     ]
    }
   ],
   "source": [
    "mean_permutation_result_gdb = pd.DataFrame({\"Feature\" : X.columns, \"permutation\" :permutation_result.importances_mean})\n",
    "print(f\"Mean of feature importance over 5 repeats \\n {mean_permutation_result_gdb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_model = RandomForestClassifier(criterion= 'gini', max_depth= 100, min_samples_split= 10, n_estimators= 500)\n",
    "rdf_model.fit(X_train, y_train)\n",
    "permutation_result = permutation_importance(rdf_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of feature importance over 5 repeats \n",
      "   Feature  permutation\n",
      "0    AGEP     0.009184\n",
      "1     COW     0.004592\n",
      "2    SCHL     0.036224\n",
      "3     MAR     0.002551\n",
      "4    OCCP     0.054082\n",
      "5    POBP     0.003061\n",
      "6    RELP     0.015816\n",
      "7    WKHP     0.050000\n",
      "8     SEX    -0.004592\n",
      "9   RAC1P     0.000510\n"
     ]
    }
   ],
   "source": [
    "mean_permutation_result_rdf = pd.DataFrame({\"Feature\" : X.columns, \"permutation\" :permutation_result.importances_mean})\n",
    "print(f\"Mean of feature importance over 5 repeats \\n {mean_permutation_result_rdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation importance: \n",
      "   Feature  Grandient Boosting  AdaBoost           SVM  Random Forest\n",
      "0    AGEP            0.007653  0.008163 -4.081633e-03       0.009184\n",
      "1     COW            0.008673 -0.004082 -9.693878e-03       0.004592\n",
      "2    SCHL            0.042857  0.019898  4.540816e-02       0.036224\n",
      "3     MAR            0.003061  0.002551  1.530612e-02       0.002551\n",
      "4    OCCP            0.044898  0.009694  2.806122e-02       0.054082\n",
      "5    POBP           -0.003061  0.004082 -5.612245e-03       0.003061\n",
      "6    RELP            0.010204  0.002041  1.173469e-02       0.015816\n",
      "7    WKHP            0.050510  0.043367  5.459184e-02       0.050000\n",
      "8     SEX            0.003061  0.002551  1.377551e-02      -0.004592\n",
      "9   RAC1P            0.000000  0.000000 -6.661338e-17       0.000510\n"
     ]
    }
   ],
   "source": [
    "permutation_df_all = pd.DataFrame({\"Feature\" : X.columns,  \n",
    "                                   \"Grandient Boosting\" : mean_permutation_result_gdb.permutation,\n",
    "                                   \"AdaBoost\": mean_permutation_result_adb.permutation,\n",
    "                                   \"SVM\": mean_permutation_result_svm.permutation,\n",
    "                                   \"Random Forest\" : mean_permutation_result_rdf.permutation})\n",
    "print(f\"Permutation importance: \\n {permutation_df_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Equité des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcul_rappel(confusion_matrix):\n",
    "    return confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcul_precision(confusion_matrix):\n",
    "    return confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_equite(confusion_matrix):\n",
    "    print(f\"Rappel = { calcul_rappel(confusion_matrix) }\" )\n",
    "    print(f\"Précision = { calcul_precision(confusion_matrix) }\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data without male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all = pd.read_csv(\"acsincome_ca_features.csv\")\n",
    "y_all = pd.read_csv(\"acsincome_ca_labels.csv\")\n",
    "index_male = X_all[X_all['SEX'] == 1].index\n",
    "\n",
    "X_all_without_male = X_all.drop(index_male)\n",
    "y_all_without_male = y_all.drop(index_male)\n",
    "\n",
    "X_all, y_all = shuffle(X_all_without_male, y_all_without_male, random_state=1)\n",
    "\n",
    "num_samples = int(len(X_all)*0.02)\n",
    "X, y = X_all[:num_samples], y_all[:num_samples]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = y_train['PINCP'].values\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = y_test['PINCP'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[215  35]\n",
      " [ 36  84]]\n",
      "Rappel = 0.7\n",
      "Précision = 0.7058823529411765\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[845 107]\n",
      " [146 379]]\n",
      "Rappel = 0.7219047619047619\n",
      "Précision = 0.779835390946502\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(C = 1, gamma= 'auto', kernel= 'rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "confusion_matrix_without_male = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = svm_model.predict(X_train)\n",
    "confusion_matrix_without_male = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rappel__ : True Positive Rate (Rappel élévé : beaucoup de vrais positifs)\n",
    "\n",
    "Rappel = TP/(TP+FN) \n",
    "\n",
    "__Précision__ : (Précision élevé : peu de faux positifs)\n",
    "\n",
    "Précision = TP/(TP+FP)\n",
    "\n",
    "Dans notre cas on a :\n",
    "\n",
    "Rappel = 87/(87+33) = 0,73\n",
    "\n",
    "Précision = 87/(87+27) = 0,76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[215  35]\n",
      " [ 36  84]]\n",
      "Rappel = 0.7\n",
      "Précision = 0.7058823529411765\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[845 107]\n",
      " [146 379]]\n",
      "Rappel = 0.7219047619047619\n",
      "Précision = 0.779835390946502\n"
     ]
    }
   ],
   "source": [
    "rdf_model = RandomForestClassifier(criterion= 'gini', max_depth= 100, min_samples_split= 10, n_estimators= 500)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "confusion_matrix_without_male = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = svm_model.predict(X_train)\n",
    "confusion_matrix_without_male = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[223  27]\n",
      " [ 39  81]]\n",
      "Rappel = 0.675\n",
      "Précision = 0.75\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[866  86]\n",
      " [126 399]]\n",
      "Rappel = 0.76\n",
      "Précision = 0.822680412371134\n"
     ]
    }
   ],
   "source": [
    "gdb_model = GradientBoostingClassifier(criterion= 'friedman_mse', learning_rate= 0.01, loss= 'deviance', n_estimators=500)\n",
    "gdb_model.fit(X_train, y_train)\n",
    "y_pred = gdb_model.predict(X_test)\n",
    "confusion_matrix_without_male = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = gdb_model.predict(X_train)\n",
    "confusion_matrix_without_male = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[225  25]\n",
      " [ 38  82]]\n",
      "Rappel = 0.6833333333333333\n",
      "Précision = 0.7663551401869159\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[834 118]\n",
      " [137 388]]\n",
      "Rappel = 0.7390476190476191\n",
      "Précision = 0.766798418972332\n"
     ]
    }
   ],
   "source": [
    "adb_model = AdaBoostClassifier(learning_rate= 0.5, n_estimators= 50)\n",
    "adb_model.fit(X_train, y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "confusion_matrix_without_male = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = adb_model.predict(X_train)\n",
    "confusion_matrix_without_male = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_male)\n",
    "cal_equite(confusion_matrix_without_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data without female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all = pd.read_csv(\"acsincome_ca_features.csv\")\n",
    "y_all = pd.read_csv(\"acsincome_ca_labels.csv\")\n",
    "index_female = X_all[X_all['SEX'] == 2].index\n",
    "\n",
    "X_all_without_female = X_all.drop(index_female)\n",
    "y_all_without_female = y_all.drop(index_female)\n",
    "\n",
    "X_all, y_all = shuffle(X_all_without_female, y_all_without_female, random_state=1)\n",
    "\n",
    "num_samples = int(len(X_all)*0.02)\n",
    "X, y = X_all[:num_samples], y_all[:num_samples]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = y_train['PINCP'].values\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = y_test['PINCP'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[180  46]\n",
      " [ 40 148]]\n",
      "Rappel = 0.7872340425531915\n",
      "Précision = 0.7628865979381443\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[777 123]\n",
      " [147 605]]\n",
      "Rappel = 0.8045212765957447\n",
      "Précision = 0.8310439560439561\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(C = 1, gamma= 'auto', kernel= 'rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "confusion_matrix_without_female = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = svm_model.predict(X_train)\n",
    "confusion_matrix_without_female = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[186  40]\n",
      " [ 42 146]]\n",
      "Rappel = 0.776595744680851\n",
      "Précision = 0.7849462365591398\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[848  52]\n",
      " [ 62 690]]\n",
      "Rappel = 0.9175531914893617\n",
      "Précision = 0.9299191374663073\n"
     ]
    }
   ],
   "source": [
    "rdf_model = RandomForestClassifier(criterion= 'gini', max_depth= 100, min_samples_split= 10, n_estimators= 500)\n",
    "rdf_model.fit(X_train, y_train)\n",
    "y_pred = rdf_model.predict(X_test)\n",
    "confusion_matrix_without_female = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = rdf_model.predict(X_train)\n",
    "confusion_matrix_without_female = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[187  39]\n",
      " [ 43 145]]\n",
      "Rappel = 0.7712765957446809\n",
      "Précision = 0.7880434782608695\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[774 126]\n",
      " [132 620]]\n",
      "Rappel = 0.824468085106383\n",
      "Précision = 0.8310991957104558\n"
     ]
    }
   ],
   "source": [
    "gdb_model = GradientBoostingClassifier(criterion= 'friedman_mse', learning_rate= 0.01, loss= 'deviance', n_estimators=500)\n",
    "gdb_model.fit(X_train, y_train)\n",
    "y_pred = gdb_model.predict(X_test)\n",
    "confusion_matrix_without_female = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = gdb_model.predict(X_train)\n",
    "confusion_matrix_without_female = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[181  45]\n",
      " [ 42 146]]\n",
      "Rappel = 0.776595744680851\n",
      "Précision = 0.7643979057591623\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[749 151]\n",
      " [138 614]]\n",
      "Rappel = 0.8164893617021277\n",
      "Précision = 0.8026143790849674\n"
     ]
    }
   ],
   "source": [
    "adb_model = AdaBoostClassifier(learning_rate= 0.5, n_estimators= 50)\n",
    "adb_model.fit(X_train, y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "confusion_matrix_without_female = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = adb_model.predict(X_train)\n",
    "confusion_matrix_without_female = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_female)\n",
    "cal_equite(confusion_matrix_without_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Métrique d'équité statique = Rappel(Taux de vrai positif) et Précision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data without 'SEX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all = pd.read_csv(\"acsincome_ca_features.csv\")\n",
    "y_all = pd.read_csv(\"acsincome_ca_labels.csv\")\n",
    "\n",
    "X_all_without_SEX = X_all.drop(columns=['SEX'])\n",
    "y_all_without_SEX = y_all\n",
    "\n",
    "X_all, y_all = shuffle(X_all_without_SEX, y_all_without_SEX, random_state=1)\n",
    "\n",
    "num_samples = int(len(X_all)*0.02)\n",
    "X, y = X_all[:num_samples], y_all[:num_samples]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = y_train['PINCP'].values\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = y_test['PINCP'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[396  64]\n",
      " [ 85 238]]\n",
      "Rappel = 0.7368421052631579\n",
      "Précision = 0.7880794701986755\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[1551  294]\n",
      " [ 294  991]]\n",
      "Rappel = 0.7712062256809339\n",
      "Précision = 0.7712062256809339\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(C = 1, gamma= 'auto', kernel= 'rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = svm_model.predict(X_train)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[402  58]\n",
      " [ 87 236]]\n",
      "Rappel = 0.7306501547987616\n",
      "Précision = 0.8027210884353742\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[1742  103]\n",
      " [ 103 1182]]\n",
      "Rappel = 0.9198443579766536\n",
      "Précision = 0.9198443579766536\n"
     ]
    }
   ],
   "source": [
    "rdf_model = RandomForestClassifier(criterion= 'gini', max_depth= 100, min_samples_split= 10, n_estimators= 500)\n",
    "rdf_model.fit(X_train, y_train)\n",
    "y_pred = rdf_model.predict(X_test)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = rdf_model.predict(X_train)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[399  61]\n",
      " [104 219]]\n",
      "Rappel = 0.6780185758513931\n",
      "Précision = 0.7821428571428571\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[1604  241]\n",
      " [ 299  986]]\n",
      "Rappel = 0.7673151750972763\n",
      "Précision = 0.8035859820700897\n"
     ]
    }
   ],
   "source": [
    "gdb_model = GradientBoostingClassifier(criterion= 'friedman_mse', learning_rate= 0.01, loss= 'deviance', n_estimators=500)\n",
    "gdb_model.fit(X_train, y_train)\n",
    "y_pred = gdb_model.predict(X_test)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = gdb_model.predict(X_train)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test: \n",
      "[[400  60]\n",
      " [112 211]]\n",
      "Rappel = 0.653250773993808\n",
      "Précision = 0.7785977859778598\n",
      "--------------------------------------------\n",
      "Confusion matrix on train: \n",
      "[[1578  267]\n",
      " [ 319  966]]\n",
      "Rappel = 0.7517509727626459\n",
      "Précision = 0.7834549878345499\n"
     ]
    }
   ],
   "source": [
    "adb_model = AdaBoostClassifier(learning_rate= 0.5, n_estimators= 50)\n",
    "adb_model.fit(X_train, y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion matrix on test: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = adb_model.predict(X_train)\n",
    "confusion_matrix_without_SEX = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion matrix on train: \")\n",
    "print(confusion_matrix_without_SEX)\n",
    "cal_equite(confusion_matrix_without_SEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
